{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4480ff39",
   "metadata": {},
   "source": [
    "<div><a href=\"https://knodis-research-group.github.io/\"><img style=\"float: right; width: 128px; vertical-align:middle\" src=\"https://knodis-research-group.github.io/knodis-logo_horizontal.png\" alt=\"KNODIS logo\" /></a>\n",
    "\n",
    "# Clasificación de texto con CNN<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Última actualización: 2025-03-14</small></i></div>\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2489222",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e17030ba",
   "metadata": {},
   "source": [
    "En el procesamiento del lenguaje natural (NLP, del inglés _natural language processing_), una tarea muy típica es la clasificación de textos. En esta tarea, un texto dado se clasifica según su significado. A menudo se utiliza, por ejemplo, para el problema del análisis de sentimientos.\n",
    "\n",
    "Se trata de un problema denominado _many-to-one_, es decir, uno en el que el tamaño de la secuencia de entrada es $T_X = 1$, pero el tamaño de la secuencia de salida es $T_Y = 1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc7d1e17",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0b9e324",
   "metadata": {},
   "source": [
    "Vamos a hacer un experimento en el que utilizaremos el conjunto de datos de reseñas de amazon para una tarea de análisis de sentimiento. A partir de los datos de reseñas y valoraciones, identificaremos si una reseña es positiva, neutra o negativa, y para ello utilizaremos una primera aproximación utilizando un modelo de redes neuronales convolucionales."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d401eac",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa528aec",
   "metadata": {},
   "source": [
    "A continuación importaremos las bibliotecas que se utilizarán a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a8c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import gzip\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff3a5f84",
   "metadata": {},
   "source": [
    "También configuraremos algunos parámetros para adaptar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d522d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ea7481e",
   "metadata": {},
   "source": [
    "Comprobamos y creamos los directorios necesarios para almacenar los datos y resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64979a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP_PATH = pathlib.Path('tmp')\n",
    "TEMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee4fec89",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6d22a2c",
   "metadata": {},
   "source": [
    "## Parámetros globales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "231d1a4e",
   "metadata": {},
   "source": [
    "Comenzaremos definiendo los parámetros que utilizaremos, como la longitud máxima de las secuencias y la dimensión de los vectores de palabras, para que  el _notebook_ se adapte lo más fácilmente posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a1ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 20           # Número de iteraciones de entrenamiento\n",
    "BATCH_SIZE = 32768      # Número de ejemplos por batch\n",
    "EMBEDDING_DIM = 50      # Dimensiones de nuestro embedding (50, 100, 200 o 300)\n",
    "MAX_VOCAB_SIZE = 20000  # Tamaño máximo de nuestro vocabulario\n",
    "MAX_SEQUENCE_LEN = 128  # Longitud máxima de las secuencias de palabras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e86b03b1",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b1ff85c",
   "metadata": {},
   "source": [
    "Vamos a cargar los datos de entrenamiento, que consistirán en los datos de reseñas de Amazon de la categoría «Música digital». Estos datos se utilizarán para entrenar nuestro modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564710a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset to /home/blazaid/Projects/aprendizaje-profundo/Notebooks/tmp/Digital_Music_5.json\n",
      "File already exists! Nice\n",
      "Loading text corpus\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "DATASET_URL = 'https://github.com/blazaid/aprendizaje-profundo/raw/refs/heads/gh-pages/Datasets/Digital_Music_5.json.gz'\n",
    "DATASET = pathlib.Path('tmp/Digital_Music_5.json')\n",
    "\n",
    "print(f\"Downloading dataset to {DATASET.resolve()}\")\n",
    "if not DATASET.exists():\n",
    "    with requests.get(DATASET_URL, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        with gzip.GzipFile(fileobj=response.raw) as f_gz:\n",
    "            with DATASET.open(\"wb\") as f:\n",
    "                shutil.copyfileobj(f_gz, f)\n",
    "else:\n",
    "    print(\"File already exists! Nice\")\n",
    "\n",
    "print(\"Loading text corpus\")\n",
    "corpus = pd.read_json(DATASET, lines=True)\n",
    "corpus.dropna(subset=['overall', 'reviewText'], inplace=True)\n",
    "corpus.head()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bace8799",
   "metadata": {},
   "source": [
    "Aquí nos centraremos en construir y entrenar un modelo basado en CNN para clasificar textos. Aunque aquí utilizamos solo un conjunto de entrenamiento, en una aplicación real sería fundamental contar con conjuntos de validación y prueba para evaluar correctamente el rendimiento del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5719ffd0",
   "metadata": {},
   "source": [
    "### Preparando la entrada a nuestro modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "074e95f9",
   "metadata": {},
   "source": [
    "Utilizaremos las reseñas de texto como entrada del modelo. Para ello, extraeremos las reseñas y transformaremos las valoraciones en etiquetas numéricas: asignaremos $0$ a reseñas con valoraciones bajas, $1$ a las intermedias y $2$ a las altas. Este paso permitirá que el modelo aprenda a distinguir entre opiniones positivas, negativas y neutrales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f62d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input shape:  (169623,)\n",
      "Training output shape: (169623,)\n",
      "No. of classes:        3\n"
     ]
    }
   ],
   "source": [
    "x_train = corpus['reviewText'].astype(str).str.strip()\n",
    "y_train = corpus['overall'].astype(int).replace({\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 1,\n",
    "    4: 2,\n",
    "    5: 2,\n",
    "})\n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "print(f\"Training input shape:  {x_train.shape}\")\n",
    "print(f\"Training output shape: {y_train.shape}\")\n",
    "print(f\"No. of classes:        {num_classes}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6464895c",
   "metadata": {},
   "source": [
    "A continuación, ya que trabajamos con texto, crearemos una función un poco más compleja que las anteriores que pasará a minúscula y extraerá palabras, separando la puntuación. Esta función nos ayudará a construir un vocabulario a partir del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3221f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b\\w+\\b|[^\\w\\s]', text, re.UNICODE)\n",
    "    return tokens\n",
    "\n",
    "counter = collections.Counter()\n",
    "for text in x_train:\n",
    "    counter.update(tokenizer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238ebee-aef6-45ca-a068-f7453ac94d77",
   "metadata": {},
   "source": [
    "De entre todas las palabras, seleccionamos las más frecuentes hasta alcanzar un límite definido. Reservamos _tokens_ especiales para el relleno (`<PAD>`) y para palabras desconocidas (`<UNK>`), lo cual es importante para el manejo de entradas de longitud fija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c07e93-baec-4e90-9202-8db4d19c8683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 20000\n"
     ]
    }
   ],
   "source": [
    "special_tokens = ['<PAD>', '<UNK>']\n",
    "\n",
    "most_common = counter.most_common(MAX_VOCAB_SIZE - len(special_tokens))\n",
    "vocab_words = [word for word, _ in most_common]\n",
    "\n",
    "vocab = {token: i for i, token in enumerate(special_tokens)}\n",
    "for i, word in enumerate(vocab_words, start=len(special_tokens)):\n",
    "    vocab[word] = i\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f'Tamaño del vocabulario: {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c08a4-22e8-4e03-9c48-8aeda4a7cbe6",
   "metadata": {},
   "source": [
    "Con la relación token$\\rightarrow$índice creada, definiremos una función que transforma cada texto en una secuencia de índices. Se aplicará relleno o truncado para que todas las secuencias tengan la misma longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc878708-089c-48bc-b3c1-ade336e17d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text, vocab, max_len=MAX_SEQUENCE_LEN):\n",
    "    tokens = tokenizer(text)\n",
    "    seq = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "    if len(seq) > max_len:\n",
    "        seq = seq[:max_len]\n",
    "    else:\n",
    "        seq = seq + [vocab['<PAD>']] * (max_len - len(seq))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ccb03-4495-4636-b3ca-6b032e25a854",
   "metadata": {},
   "source": [
    "Por último, implementamos un nuevo `Dataset`, que se encargará de gestionar y transformar los datos de las reseñas en secuencias numéricas, asociándolas con sus respectivas etiquetas. Este objeto será usado por el `DataLoader` para el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47ebe517-cee3-479d-8919-5173b72e24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=MAX_SEQUENCE_LEN):\n",
    "        self.texts = texts.tolist()\n",
    "        self.labels = labels.tolist()\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = text_to_sequence(self.texts[idx], self.vocab, self.max_len)\n",
    "        return torch.tensor(seq, dtype=torch.long), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "\n",
    "dataset = TextDataset(x_train, y_train, vocab, MAX_SEQUENCE_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7223928",
   "metadata": {},
   "source": [
    "## Uso de _embeddings_ preentrenados en nuestro modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9977840",
   "metadata": {},
   "source": [
    "Ya hemos visto que, a la hora de construir un modelo lingüístico, un aspecto importante es la representación de las palabras. Para captar el significado semántico de las palabras, utilizamos _embeddings_ de palabras, que son representaciones vectoriales de palabras en un espacio donde cada una de las muchas dimensiones representan una característica semántica.\n",
    "\n",
    "Esta vez, en lugar de entrenar nuestros _embeddings_ desde cero, aprovecharemos uno preentrenado, _Global Vectors for Word Representation_ (GLoVe), entrenado con un conjunto de datos de más de 6.000 millones de tokens. Cuenta con varios vectores de palabras preentrenados, por lo que los utilizaremos en <http://nlp.stanford.edu/data/glove.6B.zip>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b5594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking ...OK\n"
     ]
    }
   ],
   "source": [
    "GLOVE_URL = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "GLOVE_FILE = pathlib.Path('tmp/glove.6B.zip')\n",
    "\n",
    "# Download the compressed GloVe dataset (if you don't already have it)\n",
    "if not GLOVE_FILE.exists():\n",
    "    print('Downloading GloVe ...', end='')\n",
    "    with open(GLOVE_FILE, 'wb') as f:\n",
    "        r = requests.get(GLOVE_URL, allow_redirects=True)\n",
    "        f.write(r.content)\n",
    "    print('OK')\n",
    "\n",
    "# Unzip it in the directory 'glove'.\n",
    "print('Unpacking ...', end='')\n",
    "shutil.unpack_archive(GLOVE_FILE, 'tmp')\n",
    "print('OK')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39fc8ea3",
   "metadata": {},
   "source": [
    "Mediante su uso podemos aprovechar la gran cantidad de conocimiento codificado en estos _embeddings_, lo que seguramente mejore (y mucho)el rendimiento de nuestro modelo lingüístico.\n",
    "\n",
    "Ahora carguemos el _embedding_ de la dimensión especificada en la configuración. El archivo se compone de líneas de tuplas, donde el primer elemento es la palabra (en texto) y el segundo es ese vector de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b853ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe 50-d embedding... done (400000 word vectors loaded)\n"
     ]
    }
   ],
   "source": [
    "print(f'Loading GloVe {EMBEDDING_DIM}-d embedding... ', end='')\n",
    "word2vec = {}\n",
    "with open(f'tmp/glove.6B.{EMBEDDING_DIM}d.txt') as f:\n",
    "    for line in f:\n",
    "        word, vector = line.split(maxsplit=1)\n",
    "        word2vec[word] = np.fromstring(vector,'f', sep=' ')\n",
    "print(f'done ({len(word2vec)} word vectors loaded)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c6ece6e",
   "metadata": {},
   "source": [
    "Bueno, $400.000$ _tokens_ son bastantes. Como nuestro vocabulario es menor, vamos a crear una capa de incrustación más pequeña, del tamaño de nuestro vocabulario. Para ello, incluiremos en ésta sólo los vectores de las palabras que nos devolverá la capa `TextVectorization`.\n",
    "\n",
    "Comenzaremos creando la matriz de incrustación con los vectores del guante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3344464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embedding matrix with GloVe vectors... done (736 out of 20000 words unassigned)\n",
      "Embedding matrix shape (20000, 50)\n"
     ]
    }
   ],
   "source": [
    "print('Creating embedding matrix with GloVe vectors... ', end='')\n",
    "\n",
    "# Our newly created embedding: a matrix of zeros\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "\n",
    "ko_words = 0\n",
    "for word, idx in vocab.items():\n",
    "    word_glove = 'unk' if word == '<UNK>' else word\n",
    "    vector = word2vec.get(word_glove)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[idx] = vector\n",
    "    else:\n",
    "        ko_words += 1\n",
    "\n",
    "print(f'done ({ko_words} out of {len(vocab)} words unassigned)')\n",
    "print(f'Embedding matrix shape {embedding_matrix.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9f9bae0",
   "metadata": {},
   "source": [
    "Bueno, al parecer hay muchas palabras que no tienen correspondencia en el _embedding_ descargada. Después de todo $400000$ _tokens_ igual no eran tantos después de todo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b6eedd5",
   "metadata": {},
   "source": [
    "## Clasificación basada en redes neuronales convolucionales"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ee0758b",
   "metadata": {},
   "source": [
    "Utilizaremos una CNN para extraer características relevantes de las reseñas. Al representar cada texto como una «imagen» de una sola fila, la CNN puede identificar patrones y relaciones importantes entre las palabras, lo que (esperamos) ayude a la capacidad de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50554551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNClassifier(\n",
      "  (embedding): Embedding(20000, 50)\n",
      "  (convs): ModuleList(\n",
      "    (0): LazyConv1d(0, 32, kernel_size=(3,), stride=(1,))\n",
      "    (1): LazyConv1d(0, 32, kernel_size=(4,), stride=(1,))\n",
      "    (2): LazyConv1d(0, 32, kernel_size=(5,), stride=(1,))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): LazyLinear(in_features=0, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, n_classes, embedding_matrix, dropout=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Capa de embedding con los vectores de palabras ya preentrenados\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight = torch.nn.Parameter(\n",
    "            torch.tensor(embedding_matrix),\n",
    "            requires_grad=False,  # Al ser False estos parámetros no se entrenan\n",
    "        )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList([\n",
    "            torch.nn.LazyConv1d(out_channels=n_filters, kernel_size=fs)\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.fc = torch.nn.LazyLinear(out_features=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)          # (B, seq_len, embedding_dim)\n",
    "        x = x.float().transpose(1, 2)  # (B, embedding_dim, seq_len)\n",
    "\n",
    "        conv_outs = [torch.relu(conv(x)) for conv in self.convs]\n",
    "        pool_outs = [\n",
    "            torch.nn.functional.adaptive_max_pool1d(conv_out, 1).squeeze(2) \n",
    "            for conv_out in conv_outs\n",
    "        ]\n",
    "\n",
    "        x = torch.cat(pool_outs, dim=1)  # (B, n_filters*len(filter_sizes))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.fc(x)                   # (B, n_classes)\n",
    "        return logits\n",
    "\n",
    "cnn_model = CNNClassifier(\n",
    "    vocab_size,\n",
    "    EMBEDDING_DIM,\n",
    "    n_filters=32,\n",
    "    filter_sizes = [3, 4, 5],\n",
    "    n_classes=num_classes,\n",
    "    embedding_matrix=embedding_matrix,\n",
    ")\n",
    "print(cnn_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4550806",
   "metadata": {},
   "source": [
    "Ahora pasamos a entrenar el modelo. Esperemos que todo salga bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccda9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 (36.01s), Train loss: 1.0769, Train metric: 0.3386\n",
      "Epoch 2/20 (36.80s), Train loss: 0.4601, Train metric: 0.3339\n",
      "Epoch 3/20 (37.42s), Train loss: 0.3701, Train metric: 0.3333\n",
      "Epoch 4/20 (37.46s), Train loss: 0.3727, Train metric: 0.3333\n",
      "Epoch 5/20 (37.79s), Train loss: 0.3709, Train metric: 0.3333\n",
      "Epoch 6/20 (37.92s), Train loss: 0.3552, Train metric: 0.3337\n",
      "Epoch 7/20 (38.08s), Train loss: 0.3371, Train metric: 0.3337\n",
      "Epoch 8/20 (38.83s), Train loss: 0.3221, Train metric: 0.3337\n",
      "Epoch 9/20 (38.46s), Train loss: 0.3140, Train metric: 0.3334\n",
      "Epoch 10/20 (38.40s), Train loss: 0.3082, Train metric: 0.3335\n",
      "Epoch 11/20 (38.35s), Train loss: 0.3014, Train metric: 0.3338\n",
      "Epoch 12/20 (38.49s), Train loss: 0.2961, Train metric: 0.3338\n",
      "Epoch 13/20 (38.58s), Train loss: 0.2916, Train metric: 0.3334\n",
      "Epoch 14/20 (38.18s), Train loss: 0.2873, Train metric: 0.3336\n",
      "Epoch 15/20 (38.50s), Train loss: 0.2844, Train metric: 0.3336\n",
      "Epoch 16/20 (39.05s), Train loss: 0.2818, Train metric: 0.3335\n",
      "Epoch 17/20 (39.08s), Train loss: 0.2777, Train metric: 0.3339\n",
      "Epoch 18/20 (38.82s), Train loss: 0.2754, Train metric: 0.3337\n",
      "Epoch 19/20 (39.00s), Train loss: 0.2739, Train metric: 0.3336\n",
      "Epoch 20/20 (39.12s), Train loss: 0.2724, Train metric: 0.3336\n"
     ]
    }
   ],
   "source": [
    "history = utils.train(\n",
    "    cnn_model,\n",
    "    train_loader,\n",
    "    n_epochs=N_EPOCHS,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(cnn_model.parameters()),\n",
    "    metric_fn=torchmetrics.classification.MulticlassAccuracy(num_classes=num_classes),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2d17311",
   "metadata": {},
   "source": [
    "Echemos un vistazo al progreso del entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddec59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x384 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a778539-1c5d-47d8-8bbd-b4468b3826c8",
   "metadata": {},
   "source": [
    "## Evaluación de nuestro modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16b83b4",
   "metadata": {},
   "source": [
    "Veamos ahora cómo interpreta el sentimiento de una reseña buena, regular y mala extraída del sitio web de amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f0fc59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good was classified as 2\n",
      "Poor was classified as 2\n",
      "Evil was classified as 2\n"
     ]
    }
   ],
   "source": [
    "good = (\"My nephew is on the autism spectrum and likes to fidget with things so I knew this toy would be a hit. \"\n",
    "        \"Was concerned that it may not be \\\"complex\\\" enough for his very advanced brain but he really took to it. \"\n",
    "        \"Both him (14 yrs) and his little brother (8 yrs) both enjoyed playing with it throughout Christmas morning. \"\n",
    "        \"I'm always happy when I can find them something unique and engaging.\")\n",
    "\n",
    "poor = (\"I wasn't sure about this as it's really small. I bought it for my 9 year old grandson. \"\n",
    "        \"I was ready to send it back but my daughter decided it was a good gift so I'm hoping he likes it. \"\n",
    "        \"Seems expensive for the price though to me.\")\n",
    "\n",
    "evil = (\"I just wanted to follow up to say that I reported this directly to the company and had no response. \"\n",
    "        \"I have not gotten any response from my review. The level of customer service goes a long way when an item \"\n",
    "        \"you purchase is defective and this company didn’t care to respond. No I am even more Leary about ordering \"\n",
    "        \"anything from this company. I never asked for a refund or replacement since I am not able to return it. \"\n",
    "        \"I’m just wanted to let them know that this was a high dollar item and I expected it to be a quality item. \"\n",
    "        \"Very disappointed! I bought this for my grandson for Christmas. He loved it and played with it a lot. \"\n",
    "        \"My daughter called to say that the stickers were peeling on the corners. I am not able to take it from my \"\n",
    "        \"grandson because he is autistic and wouldn’t understand. I just wanted to warn others who are wanting to get \"\n",
    "        \"this. Please know that this is a cool toy and it may not happen to yours so it is up to you.\")\n",
    "\n",
    "def predict_text(text, model, vocab):\n",
    "    model.eval()\n",
    "    seq = text_to_sequence(text, vocab, MAX_SEQUENCE_LEN)\n",
    "    seq_tensor = torch.tensor(seq, dtype=torch.long).unsqueeze(0)  # crear batch de 1\n",
    "    with torch.no_grad():\n",
    "        logits = model(seq_tensor)\n",
    "        pred = logits.argmax(dim=1).item()\n",
    "    return pred\n",
    "\n",
    "print(f'Good was classified as {predict_text(good, cnn_model, vocab)}')\n",
    "print(f'Poor was classified as {predict_text(poor, cnn_model, vocab)}')\n",
    "print(f'Evil was classified as {predict_text(evil, cnn_model, vocab)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43585490",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7defd88",
   "metadata": {},
   "source": [
    "Hemos demostrado cómo utilizar una red neuronal convolucional para clasificar texto, en concreto, reseñas de productos como buenas, medias o malas. También hemos analizado las ventajas de utilizar incrustaciones de palabras preentrenadas, que pueden ayudar a mejorar el rendimiento del modelo aprovechando las relaciones semánticas entre las palabras del corpus preentrenado. También exploramos la capa TextVectorization, que proporciona una forma flexible de preprocesar datos de texto y convertirlos en vectores numéricos.\n",
    "\n",
    "Se trata de un ejemplo que puede servir de punto de partida para multitud de proyectos de NLP."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33005bde",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
