{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "# Apilando redes recurrentes<a id=\"top\"></a>\n",
    "\n",
    "<i>Última actualización: 2025-03-03</small></i></div>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las RNN apiladas (del inglés _stacked_) son un tipo de red neuronal formada por múltiples capas de RNN apiladas unas sobre otras. Se ha demostrado que las RNN apiladas mejoran el rendimiento de las RNN en diversas tareas al permitir que la red aprenda representaciones más complejas de datos secuenciales.\n",
    "\n",
    "En una RNN apilada, la salida de una capa de la RNN se pasa como entrada a la capa siguiente, creando una representación jerárquica de la secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este _notebook_ resolveremos un problema anterior con este tipo de arquitectura, viendo cómo implementar un modelo con varias capas recurrentes superpuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación importaremos las librerías que se utilizarán a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchsummary\n",
    "import torchvision\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También configuraremos algunos parámetros para adaptar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, establecemos las constantes de los recursos comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = './tmp'\n",
    "BATCH_SIZE = 8192\n",
    "TRAIN_EPOCHS = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y preproceso de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez más, utilizaremos el conjunto de datos _fashion_ MNIST porque es mola bastante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=DATASETS_DIR,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root=DATASETS_DIR,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo basado en múltiples capas de `RNN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En una arquitectura multicapa, **cada capa recurrente procesa una secuencia de entradas** y, al configurarlas para que devuelvan la secuencia completa, la siguiente capa también puede recibir una secuencia.\n",
    "\n",
    "En PyTorch, el comportamiento por defecto de las `RNN` (por ejemplo, `torch.nn.RNN`) es devolver la secuencia completa, es decir, un tensor de forma `(batch_size, sequence_len, num_features)`. Por lo tanto, al apilar capas recurrentes, basta con pasar la salida completa de la primera capa como entrada a la siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.rnn1 = torch.nn.RNN(input_size=28, hidden_size=8, batch_first=True)\n",
    "        self.rnn2 = torch.nn.RNN(input_size=8, hidden_size=8, batch_first=True)\n",
    "        self.rnn3 = torch.nn.RNN(input_size=8, hidden_size=8, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(in_features=8, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        out, _ = self.rnn1(x)\n",
    "        out, _ = self.rnn2(out)\n",
    "        out, _ = self.rnn3(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNNModel()\n",
    "torchsummary.summary(model, input_size=(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener cuidado porque en Keras el comportamiento es el contrario. Las unidades recurrentes devuelven únicamente el último valor, y es necesario usar el parámetro `return_sequences=True` para que el comportamiento sea el de devolver una secuencia con cada una de las inferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por último, entrenaremos nuestra red durante $10$ epochs. Sí, si con las redes recurrentes era lento, con las redes apiladas lo es aún más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = utils.train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    n_epochs=TRAIN_EPOCHS,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters()),\n",
    "    validation_split=0.1,\n",
    "    metric_fn=torchmetrics.classification.MulticlassAccuracy(num_classes=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Veamos cómo ha ido el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizá la precisión con la que ha clasificado sea mejor, pero en este problema concreto, las redes convolucionales siguen siendo la mejor opción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de nuevas muestras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora imprimiremos algunos de los elementos de la prueba para ver cómo se han clasificado y cuáles han sido los errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS, COLS = 5, 5\n",
    "IMAGES = ROWS * COLS\n",
    "\n",
    "images, labels = [], []\n",
    "for i in range(IMAGES):\n",
    "    img, label = test_set[i]\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "images_tensor = torch.stack(images)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images_tensor)\n",
    "    preds = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i, (img, true_label, pred_label) in enumerate(zip(images_tensor, labels, preds), 1):\n",
    "    ax = fig.add_subplot(ROWS, COLS, i)\n",
    "    img_np = img.squeeze(0).numpy()\n",
    "    ax.imshow(img_np, cmap='Greens' if true_label == pred_label else 'Reds')\n",
    "    ax.set_title(f'Expected: {true_label}, Predicted: {pred_label}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos mostrado cómo implementar una red neuronal recurrente apilada en PyTorch, concretamente un modelo RNN de dos capas con $8$ unidades en cada capa. Y aunque lo hemos aplicado al problema _fashion MNIST, hemos comprobado que no es la mejor opción (al menos en tiempo de entrenamiento). Sin embargo, apilar RNN puede ser una técnica muy útil para modelar datos secuenciales, ya que permite al modelo capturar dependencias más complejas entre las entradas y las salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
