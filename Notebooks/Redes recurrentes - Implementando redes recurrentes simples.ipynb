{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "# Implementado redes recurrentes simples<a id=\"top\"></a>\n",
    "\n",
    "<i>Última actualización: 2025-03-03</small></i></div>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las redes neuronales recurrentes (RNN, del inglés _recurrent neural networks_) son un tipo de red neuronal que se utiliza para procesar datos secuenciales. A diferencia de las redes neuronales tradicionales, las RNN tienen conexiones entre los nodos que permiten que la información pase de un paso al siguiente. Esto las hace especialmente útiles para procesar datos que tienen una estructura temporal o secuencial, como las series temporales, el habla y el texto.\n",
    "\n",
    "La idea básica de las RNN es utilizar la salida del paso anterior como entrada para el paso actual. Esto crea un bucle de retroalimentación que permite a la red mantener información sobre la secuencia que ha procesado hasta el momento. En su forma más simple, se implementan mediante unidades recurrentes simples (SRU). Las SRU son a las RNN lo que las neuronas son a las redes neuronales tradicionales. La única diferencia es que la salida de la red se concatena con la entrada, de modo que la salida anterior forma parte de la entrada actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este _notebook_ vamos a implementar una RNN para resolver el problema [_Fashion MNIST_](https://github.com/zalandoresearch/fashion-mnist). Aunque _Fashion MNIST_ es tradicionalmente un problema de clasificación de imágenes, lo utilizaremos como ejercicio para demostrar cómo una RNN puede procesar la imagen de una prenda leyendo sus filas de arriba a abajo, consiguiendo resultados comparables a los de las redes de convolución (CNN).\n",
    "\n",
    "Al final habremos aprendido a:\n",
    "\n",
    "- Crear y entrenar un modelo recurrente para resolver problemas de clasificación utilizando, para ello, una unidad recurrente simple (`RNN` en PyTorch).\n",
    "- Apilar dos o más `RNN` para hacer redes recurrentes, aumentando así la potencia de estas redes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación importaremos las bibliotecas que se utilizarán a lo largo del cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchsummary\n",
    "import torchvision\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También configuraremos algunos parámetros para adaptar la presentación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, establecemos las constantes de los recursos comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = './tmp'\n",
    "BATCH_SIZE = 1024\n",
    "TRAIN_EPOCHS = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos como en el resto de _notebooks_, descargando y preparando el conjunto `mnist` para nuestra tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root=DATASETS_DIR,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root=DATASETS_DIR,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo basado en una capa de SRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La primera capa se implementará como una RNN simple en PyTorch (usando `torch.nn.RNN`) con $10$ unidades ocultas. La entrada a esta capa serán las filas de la imagen, es decir, cada imagen se considerará como una secuencia de $28$ pasos, donde cada paso tiene $28$ características (los píxeles de cada fila).\n",
    "\n",
    "La segunda capa será una capa lineal (implementada con `torch.nn.Linear`) que mapea los $10$ valores de salida de la `RNN` a $10$ neuronas, una para cada clase. En términos de conexiones, esto equivale a tener $10 \\times 10 + 10$  conexiones ($10$ pesos por cada una de las $10$ unidades, más 10 bias).\n",
    "\n",
    "En este caso, en lugar de encadenar las capas con `torch.nn.Sequential`, definiremos la arquitectura creando una subclase de `torch.nn.Module`. Esto nos permitirá definir un método `forward` en el que podremos: (i) procesar la entrada a través de la `RNN`, (ii) seleccionar la salida correspondiente al último step temporal, y (iii) pasar esta salida por la capa lineal para  obtener las predicciones finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.rnn = torch.nn.RNN(\n",
    "            input_size=28,  # Cada fila  de la imagen\n",
    "            hidden_size=8,  # Número de unidades (neuronas) de salida\n",
    "            batch_first=True,  # Queremos formato (batch, sec_len, n_feat)\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(in_features=8, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)  # Nos viene con la información del canal, pero RNN\n",
    "                          #  espera (batch, seq_len, features), así que nos\n",
    "                          #  información de canal\n",
    "        out, _ = self.rnn(x)  # La segunda salida es la salida final.\n",
    "        out = out[:, -1, :]  # (batch, sec_len, n_feat) -> La última inferencia,\n",
    "                             #  es decir, sería lo mismo a la segunda salida de\n",
    "                             #  rnn\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNNModel()\n",
    "torchsummary.summary(model, input_size=(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por último, entrenaremos nuestra red. Cuidado con el tiempo de entrenamiento, ya que en el caso de las redes recurrentes es bastante lento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = utils.train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    n_epochs=TRAIN_EPOCHS,\n",
    "    criterion=torch.nn.CrossEntropyLoss(),\n",
    "    optimizer=torch.optim.Adam(model.parameters()),\n",
    "    validation_split=0.1,\n",
    "    metric_fn=torchmetrics.classification.MulticlassAccuracy(num_classes=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Veamos cómo ha evolucionado la formación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history).plot()\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que están lejos de las precisiones conseguidas con otras técnicas de aprendizaje profundo, especialmente si las comparamos con las redes convolucionales. Pero como hemos dicho, se trata de un ejemplo de implementación, no de un caso de uso concreto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de ropajes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer algunas inferencias sobre el conjunto de datos de prueba. Veremos que nuestro modelo falla significativamente más que en otros casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS, COLS = 5, 5\n",
    "IMAGES = ROWS * COLS\n",
    "\n",
    "images, labels = [], []\n",
    "for i in range(IMAGES):\n",
    "    img, label = test_set[i]\n",
    "    images.append(img)\n",
    "    labels.append(label)\n",
    "\n",
    "images_tensor = torch.stack(images)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images_tensor)\n",
    "    preds = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i, (img, true_label, pred_label) in enumerate(zip(images_tensor, labels, preds), 1):\n",
    "    ax = fig.add_subplot(ROWS, COLS, i)\n",
    "    img_np = img.squeeze(0).numpy()\n",
    "    ax.imshow(img_np, cmap='Greens' if true_label == pred_label else 'Reds')\n",
    "    ax.set_title(f'Expected: {true_label}, Predicted: {pred_label}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos aprendido a implementar una RNN simple en Keras, construyendo un modelo sencillo para clasificar las imágenes `mnist` en sus correspondientes etiquetas, demostrando cómo compilar y entrenar el modelo, y cómo evaluar su rendimiento utilizando la exactitud (_accuracy_) como métrica. En realidad, hemos hecho lo que hasta ahora, pero con redes recurrentes, y hemos visto que es prácticamente igual.\n",
    "\n",
    "Pero al menos hemos aprendido que se puede hacer y que es fácil. Est _notebook_ nos sirve como punto de partida para implementar modelos RNN más complejos en Keras para tareas como la predicción de series temporales o el procesamiento del lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
