{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010176d1",
   "metadata": {},
   "source": [
    "<div><img style=\"float: right; width: 120px; vertical-align:middle\" src=\"https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/EU_Informatica/ETSI%20SIST_INFORM_COLOR.png\" alt=\"ETSISI logo\" />\n",
    "\n",
    "# Perceptrón simple y perceptrón multicapa<a id=\"top\"></a>\n",
    "\n",
    "<i><small>Última actualización: 2025-02-26</small></i></div>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fb61b",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c114e",
   "metadata": {},
   "source": [
    "En el mundo del aprendizaje profundo (DL, del inglés _deep learning_), el perceptrón y el perceptrón multicapa son conceptos básicos para entender las redes neuronales. El perceptrón ([introducido por Frank Rosenblatt en 1957](https://psycnet.apa.org/doi/10.1037/h0042519)) es un modelo simple para clasificar en dos grupos. Aunque tiene limitaciones (por ejemplo, no puede resolver problemas no lineales como la puerta XOR), sienta las bases para modelos más complejos. El perceptrón multicapa agrega una o más capas ocultas, lo que permite modelar relaciones no lineales y resolver problemas más complicados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f243ba3",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc68420",
   "metadata": {},
   "source": [
    "Los objetivos que trataremos de cubrir en este _notebook_ son los siguientes:\n",
    "\n",
    "1. Explicar qué es un perceptrón y un perceptrón multicapa.\n",
    "2. Describir cómo funciona cada modelo (neuronas, pesos, sesgos y funciones de activación).\n",
    "3. Implementar ambos modelos desde cero usando Python y numpy.\n",
    "3. Mostrar cómo usar torch para crear y entrenar redes neuronales de forma más sencilla.\n",
    "4. Aplicar estos modelos a problemas prácticos (por ejemplo, clasificación de dígitos con MNIST)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67582fcc",
   "metadata": {},
   "source": [
    "## Bibliotecas y configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec4713-19b6-49de-bc5d-87e0bed944e4",
   "metadata": {},
   "source": [
    "Primero, importamos las bibliotecas necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58374f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchsummary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1716ef",
   "metadata": {},
   "source": [
    "Configuramos también algunos parámetros para las gráficas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f428e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'figure.figsize': (20, 6),'figure.dpi': 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014b16d-744d-4bfa-a5d4-5960e7e2614b",
   "metadata": {},
   "source": [
    "Por último, establecemos las constantes de los recursos comunes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be1325-5b75-4d71-bdf5-e11af8943c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = './tmp'  # Directorio donde se almacenarán los conjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06541e93",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7467c",
   "metadata": {},
   "source": [
    "## Perceptrón simple (Implementación desde cero con numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16f318",
   "metadata": {},
   "source": [
    "El perceptrón simple, también conocido simplemente como perceptrón, es un modelo de aprendizaje automático lineal que se utiliza para clasificaciones binarias. Este modelo fue desarrollado en 1957 por Frank Rosenblatt y puede considerarse como la **unidad básica de una red neuronal artificial**. La idea central detrás del perceptrón es simular el funcionamiento de una neurona biológica, donde recibe múltiples señales de entrada, las procesa y produce una salida única. En términos matemáticos, el perceptrón toma un vector de características de entrada, les aplica pesos correspondientes, suma estos productos y luego aplica una función de activación, típicamente la función escalón, para determinar si la entrada pertenece a una clase o a otra. Llamaremos de ahora en adelante a este proceso **inferencia**.\n",
    "\n",
    "El funcionamiento del perceptrón se basa en la actualización iterativa de los pesos asociados a cada característica de entrada. Durante el proceso de entrenamiento, el modelo ajusta estos pesos para minimizar el error en sus predicciones. Si la predicción es incorrecta, los pesos se actualizan en función del error cometido, utilizando una tasa de aprendizaje para controlar la magnitud del ajuste. Esta regla de aprendizaje, conocida como regla de aprendizaje del perceptrón o **regla delta**, permite al modelo aprender la frontera de decisión que mejor separa las dos clases. A pesar de su simplicidad y de estar limitado a problemas linealmente separables, el perceptrón sienta las bases para algoritmos más complejos y constituye el primer paso hacia el entendimiento de las redes neuronales multicapa y el aprendizaje profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cfe2d",
   "metadata": {},
   "source": [
    "### Inferencia en el perceptrón"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239527e",
   "metadata": {},
   "source": [
    "En la definición original del perceptrón simple, el proceso de inferencia (suma de las entradas ponderadas por sus respectivos pesos. Esta función es la función escalón, que devuelve 1 si la suma es mayor que un umbral $\\mathcal{U}$ y 0 en caso contrario. Matemáticamente, la salida $\\hat{y}$ de un perceptrón simple se calcula como sigue:\n",
    "\n",
    "$$\n",
    "\\hat{y} = f_a(X \\cdot W) = f_a\\left(\\sum_{i=0}^{n} x_i w_i + b\\right)\n",
    "$$\n",
    "\n",
    "La matriz de pesos tendrá tantas filas como componentes tiene el vector de entrada. De hecho, podemos tener varias salidas (neuronas) diferentes, por lo que si tenemos más de una, la matriz $W$ tendrá tantas columnas como valores de salida\n",
    "\n",
    "Este proceso se conoce como «inferencia». Vamos a implementarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d23bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        # W: (filas + 1 (bias), columnas)\n",
    "        self.W = np.random.uniform(-0.5, 0.5, (n_inputs + 1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función escalón\n",
    "        return np.piecewise(X, [X <= 0, 0 < X], [0, 1])\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Calculamos la entrada neta\n",
    "        Z = X @ self.W\n",
    "        # Aplicamos la función de activación\n",
    "        return self.activation(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48361b",
   "metadata": {},
   "source": [
    "Su funcionamiento sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5039f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos las entradas (3)\n",
    "X = np.array([1, 2, 3])\n",
    "# Creamos el modelo, del que obtendremos dos salidas dadas las entradas\n",
    "model = Perceptron(n_inputs=3, n_outputs=2)\n",
    "# Inferimos a ver qué sale\n",
    "ŷ = model.inference(X)\n",
    "print(ŷ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3f9ba",
   "metadata": {},
   "source": [
    "Fantástico, ya tenemos un perceptrón. ¿Para qué nos vale? Realmente para nada. Los valores de los pesos se han inicializado aleatoriamente. Si queremos que de verdad de respuestas a un problema tenemos dos opciones:\n",
    "\n",
    "1. Poner los valores de los pesos nosotros a mano (tedioso, sobre todo si la matriz de pesos es muy grande).\n",
    "2. Que se pongan automáticamente de acuerdo al problema.\n",
    "\n",
    "Evidentemente este segundo paso es el que queremos. De hecho, este paso es lo que hace que estos modelos estén dentro del área del «aprendizaje automático». La neurona va a aprender automáticamente a dar buenos resultados (o al menos lo va a intentar).\n",
    "\n",
    "El esquema de entrenamiento será de **aprendizaje supervisado**, esto es, el modelo aprenderá a partir de un conjunto de datos en el que se encuentran tanto los valores de entrada como los valores de salida esperados a dichas entradas.\n",
    "\n",
    "El algoritmo que usaremos será la [regla delta](https://en.wikipedia.org/wiki/Delta_rule)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598dfdc",
   "metadata": {},
   "source": [
    "### Regla delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866b614",
   "metadata": {},
   "source": [
    "Disponemos de una implementación para la inferencia de un perceptrón, pero no sabemos los pesos. Para ello, vamos a introducir un algoritmo a través del cual, disponiendo de un conjunto de datos con entradas y salidas esperadas, tratará de encontrar los pesos idóneos para aproximar los valores todo lo posible a los presentados.\n",
    "\n",
    "La regla delta calcula cómo tienen que variar los pesos actuales en función del error que se ha cometido. Esta variación obedece a las siguientes ecuaciones:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\Delta W       &= \\alpha X^t (y - \\hat{y}) \\\\\n",
    "\\Delta \\vec{b} &= \\alpha (y - \\hat{y})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $\\alpha$: El factor de aprendizaje, generalmente en el intervalo $(0, 1)$\n",
    "- $X^t$: La traspuesta de las entradas.\n",
    "- $y$ e $\\hat{y}$: Las salidas esperada y real de la red, respectivamente.\n",
    "\n",
    "Como se puede observar, la cantidad que variarán los pesos son directamente proporcionales al error cometido (i.e. cuanto mayor es el error más varían) y a la entrada (i.e. cuanto mayor es la entrada, más ha influido en el error).\n",
    "\n",
    "Tras calcular esa variación, basta con sumársela a los pesos para obtener los nuevos, tal y como se expresa a continuación:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "W_{t+1}       &= W_{t}       + \\Delta W_{t+1} \\\\\n",
    "\\vec{b_{t+1}} &= \\vec{b_{t}} + \\Delta \\vec{b_{t}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Vamos a implementar el cálculo de los errores en un nuevo método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ee69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        self.W = np.random.uniform(-0.5, 0.5, (n_inputs + 1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función escalón\n",
    "        return np.piecewise(X, [X <= 0, 0 < X], [0, 1])\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Calculamos la entrada neta\n",
    "        Z = X @ self.W\n",
    "        # Aplicamos la función de activación\n",
    "        return self.activation(Z)\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos cuál es la salida para la entrada suministrada\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ella, calculamos el error cometido\n",
    "        error = y - ŷ\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Con el error y las entradas, calculamos lo que variarán los pesos\n",
    "        delta_W = alpha * X.T @ error\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        self.W = self.W + delta_W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97eb38",
   "metadata": {},
   "source": [
    "**NOTA**: Hay un if donde se llama a la función `expand_dims`. Esto es debido a que, cuando el vector de entrada es es un array de una dimensión, cuando se le pide las traspuesta (con `.T`) numpy nos devuelve el mismo vector, sin trasponer, por lo que antes de pedir la traspuesta nos aseguramos de que tiene al menos dos dimensiones. Esto convertiría, por ejemplo, la entrada `[0, 1]` (una dimensión) en la entrada `[[0, 1]]` (dos dimensiones).\n",
    "\n",
    "Con este cálculo, conseguimos que los pesos se acerquen un poquito hacia valores que producen salidas con menor error. Veamos cómo se usaría:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89015093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entradas para la puera OR\n",
    "X = np.array([[0, 0],\n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "# Salidas esperadas para cada una de las entradas\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1]])\n",
    "# Creamos el modelo, del que obtendremos dos salidas dadas las entradas\n",
    "model = Perceptron(n_inputs=2, n_outputs=1)\n",
    "# Veamos sus pesos y salidas correspondientes\n",
    "print(f'Pesos antes de \"learn\":\\n {model.W}')\n",
    "print(f'Salida para {X[0]}: {model.inference(X[0])} (esperada {y[0]})')\n",
    "print(f'Salida para {X[1]}: {model.inference(X[1])} (esperada {y[1]})')\n",
    "print(f'Salida para {X[2]}: {model.inference(X[2])} (esperada {y[2]})')\n",
    "print(f'Salida para {X[3]}: {model.inference(X[3])} (esperada {y[3]})')\n",
    "# Ahora, a aprender de nuestro errores\n",
    "model.learn(X[0], y[0], alpha=0.5)\n",
    "model.learn(X[1], y[1], alpha=0.5)\n",
    "model.learn(X[2], y[2], alpha=0.5)\n",
    "model.learn(X[3], y[3], alpha=0.5)\n",
    "print(f'Pesos después de \"learn\":\\n {model.W}')\n",
    "print(f'Salida para {X[0]}: {model.inference(X[0])} (esperada {y[0]})')\n",
    "print(f'Salida para {X[1]}: {model.inference(X[1])} (esperada {y[1]})')\n",
    "print(f'Salida para {X[2]}: {model.inference(X[2])} (esperada {y[2]})')\n",
    "print(f'Salida para {X[3]}: {model.inference(X[3])} (esperada {y[3]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da79db",
   "metadata": {},
   "source": [
    "Podemos ver que los pesos han cambiado y, a lo mejor, que las predicciones son más certeras. Un par de apuntes:\n",
    "\n",
    "- Hemos enseñado los cuatro ejemplos de nuestro conjunto de entrenamiento (sí, se llama conjunto de entrenamiento al conjunto con el que entrenamos, en aprendizaje automático somos así de originales). A esto se le conoce como _epoch_. Los entrenamientos se miden en epochs.\n",
    "- La implementación que hemos hecho permite trabajar con matrices en la entrada y salida. Esto quiere decir que el anterior _epoch se podría haber implementado así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b899b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron(n_inputs=2, n_outputs=1)\n",
    "print(f'Pesos antes de \"learn\":\\n {model.W}')\n",
    "model.learn(X, y, alpha=0.5)\n",
    "print(f'Pesos después de \"learn\":\\n {model.W}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eb05aa",
   "metadata": {},
   "source": [
    "Así completamos un epoch en mucho menos tiempo. De hecho, las tarjetas gráficas hacen las operaciones con matrices extremadamente rápidas, y es por ello por lo que se usan tanto en aprendizaje automático.\n",
    "\n",
    "Y ahora que las redes saben aprender de sus errores, vamos a escribir el proceso por el cual aprenderán (o lo intentarán) todo el problema. A este proceso se le llama entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b6a82",
   "metadata": {},
   "source": [
    "### Entrenamiento de un perceptrón\n",
    "\n",
    "El proceso de entrenamiento es realizar _epochs_ de aprendizaje uno detrás de otro hasta que la red haya aprendido lo que queremos que sepa hacer. O al menos hasta que lo haga «suficientemente» bien. ¡O no! porque siempre puede pasar que la red no aprenda.\n",
    "\n",
    "Aquí vamos a usar como condición de parada un número fijo de _epochs_. Crearemos un nuevo método que llamaremos `train` que entrenará el modelo un número determinado de `epochs` sobre un conjunto de datos de entrenamiento  `X, y` y con un factor de aprendizaje `alpha`.\n",
    "\n",
    "Aprovecharemos y añadiremos un parámetro opcional, `trace`, que indicará cada cuantos epochs nos muestra información por pantalla. Por el momento nos ceñiremos la medida de exactitud (_accuracy_) que es el número resultados acertados con respecto del total. Vamos allá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaeaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        # Matriz de pesos: (filas: entradas, columnas: salidas, +1: bias)\n",
    "        self.W = np.random.uniform(-0.5, 0.5, (n_inputs + 1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función escalón\n",
    "        return np.piecewise(X, [X <= 0, 0 < X], [0, 1])\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Calculamos la entrada neta\n",
    "        Z = X @ self.W\n",
    "        # Aplicamos la función de activación\n",
    "        return self.activation(Z)\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos cuál es la salida para la entrada suministrada\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ella, calculamos el error cometido\n",
    "        error = y - ŷ\n",
    "        # Añadimos una columna entera de 1s (la entrada del bias)\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        # Con el error y las entradas, calculamos lo que variarán los pesos\n",
    "        delta_W = alpha * X.T @ error\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        self.W = self.W + delta_W\n",
    "    \n",
    "    def train(self, X, y, epochs, alpha, trace=1):\n",
    "        for epoch in range(0, epochs):\n",
    "            if epoch % trace == 0:\n",
    "                print(f'Epoch {epoch}: Accuracy: {self.accuracy(X, y)}')\n",
    "            self.learn(X, y, alpha)\n",
    "        print(f'End -> {epochs} epochs, accuracy: {self.accuracy(X, y)}')\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        ŷ = self.inference(X)\n",
    "        return (y == ŷ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46d5ec",
   "metadata": {},
   "source": [
    "Ahora vamos a probar a entrenar nuestro perceptrón para una puerta AND de tres entradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e832a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_AND = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [1, 0, 1, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [1, 1, 1, 1],\n",
    "])\n",
    "X = DATASET_AND[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_AND[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = Perceptron(n_inputs=3, n_outputs=1)\n",
    "model.train(X, y, 100, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d48fee",
   "metadata": {},
   "source": [
    "Bueno, parece que aprende. Vamos a la principal limitación de este modelo. ¿qué pasaría si intentamos entrenar una puerta XOR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = Perceptron(n_inputs=2, n_outputs=1)\n",
    "model.train(X, y, 100, 0.1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025fb615",
   "metadata": {},
   "source": [
    "Da igual el número de _epochs_, factor de aprendizaje o parámetros que usemos. La red nunca aprenderá. La explicación es la siguiente:\n",
    "\n",
    "**Un perceptrón es un [clasificador lineal](https://es.wikipedia.org/wiki/Clasificador_lineal)**, lo que quiere decir que clasifica basándose en la combinación lineal de las entradas. Dicho de otro modo, tiene que haber una recta en el plano (o un plano en un espacio, o ...) que separe los diferentes ejemplos a un lado y a otro.\n",
    "\n",
    "¿Y esto qué? Bueno, el problema con la puerta XOR se ve muy fácilmente en la siguiente imagen:\n",
    "\n",
    "<center>\n",
    "<figure class=\"image\">\n",
    "    <img src=\"images/puertas-or-y-xor.png\" alt=\"Representación en el plano de las puertas OR y XOR\" />\n",
    "    <figcaption><em><strong>Figura 1.</strong>Hay problemas muy simples que no son separables linealmente.</em></figcaption>\n",
    "</figure>\n",
    "</center>\n",
    "\n",
    "Para la puerta OR es fácil encontrar una línea que separe los ejemplos cuyo valor es 1 de los ejemplos cuyo valor es 0. Para la puerta XOR es imposible. A estos problemas se los denomina, respectivamente, separables y no separables linealmente. Y el problema es que en el mundo real apenas hay problemas que sean separables linealmente, por lo que un perceptrón simple no suele ser la mejor opción casi nunca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c97b9",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa (Implementación desde cero con numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa06ce",
   "metadata": {},
   "source": [
    "El perceptrón multicapa (MLP, del inglés _multilayer perceptron_), representa una evolución significativa del perceptrón simple hacia una arquitectura capaz de abordar la complejidad inherente a problemas no linealmente separables. A diferencia de su predecesor, el MLP incorpora una o más capas ocultas entre la capa de entrada y la capa de salida, lo que le permite modelar funciones no lineales y realizar tareas de clasificación y regresión más sofisticadas.\n",
    "\n",
    "Cada neurona en estas capas ocultas realiza cálculos similares a los del perceptrón simple, pero la introducción de múltiples capas y la aplicación de **funciones de activación no lineales**, como la función sigmoide, ReLU o tangente hiperbólica, en cada neurona, permiten a la red aprender patrones complejos en los datos.\n",
    "\n",
    "El entrenamiento de un perceptrón multicapa se realiza a través del algoritmo de retropropagación, un método que ajusta los pesos de la red de manera iterativa con el objetivo de minimizar la diferencia entre las salidas predichas y las salidas reales (error). Este proceso involucra el cálculo del gradiente de la función de pérdida respecto a cada peso en la red, utilizando el cálculo diferencial, y la actualización de los pesos en la dirección que reduce el error. Gracias a esta capacidad de ajuste fino y a la flexibilidad arquitectónica, los perceptrones multicapa han encontrado aplicaciones en una amplia gama de campos, desde el reconocimiento de voz y de imágenes hasta la modelización del lenguaje natural y la predicción de series temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103e3f5",
   "metadata": {},
   "source": [
    "### ¿Por qué esas dos diferencias cambian tanto el comportamiento de las redes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c68b7",
   "metadata": {},
   "source": [
    "Las dos diferencias (varias capas y función de activación no lineal) trabajan conjuntamente para abordar el problema de la no linealidad.\n",
    "\n",
    "Comencemos con el perceptrón de una sola capa. Aunque tengamos varias neuronas en esa capa, cada una funcionará independiente de las demás y decisión será lineal. Por tanto, por muchas neuronas que tenga, podremos dividir el espacio de entrada en muchas regiones diferentes, pero los límites de estas regiones estarán limitadas a dichos planos, por lo que podrán clasificar más de dos grupos, pero los grupos deberán ser linealmente separables.\n",
    "\n",
    "¿Y por qué no basta con añadir más capas? ¿Por qué ese requisito de la no linealidad en las funciones de activación? Bueno, la respuesta es que una combinación lineal de funciones lineales sigue siendo una función lineal. Veámoslo con matrices que intimida más aunque es más sencillo:\n",
    "\n",
    "Una función lineal $f_a$ tiene siempre una matriz asociada a la que llaaremos $M_a$. Ahora, recordemos la fórmula de la salida $ŷ$ de un perceptrón en función de su entrada $X$ con una activación lineal $f_a$:\n",
    "\n",
    "$$\n",
    "ŷ = f_a(X \\cdot W)\n",
    "$$\n",
    "\n",
    "Si tenemos varias capas, digamos 2, la salida de una capa será la entrada de la siguiente, por lo que la función de salida quedaría como sigue:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S^{(1)} &= f_a(X \\cdot W^{(1)}) \\\\\n",
    "S^{(2)} &= f_a(S^{(1)} \\cdot W^{(2)}) = ŷ \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Ahora bien, dado que la función de activación $f_a$ es lineal, tiene una matriz asociada, por lo que podemos reemplazar la función con un producto de matrices:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "ŷ &= f_a(S^{(1)} \\cdot W^{(2)}) \\\\\n",
    "  &= W_a \\cdot S^{(1)} \\cdot W^{(2)} \\\\\n",
    "  &= W_a \\cdot W_a \\cdot X \\cdot W^{(1)} W^{(2)} \\\\\n",
    "  &= W'_a \\cdot X \\cdot W'^{(1)} \\\\\n",
    "  &= f_a' (X \\cdot W'^{(1)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Sin funciones de activación no lineales, el perceptrón multicapa no podrá aprender relaciones no lineales de los datos, básicamente tendría las mismas capacidades que una red con una sola capa. Así que si hay una relación no lineal entre la entrada y la salida, o hay interacciones entre las variables, la red no será capaz de aprenderlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70305b8",
   "metadata": {},
   "source": [
    "### Inferencia en el perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e970bf",
   "metadata": {},
   "source": [
    "La inferencia es similar a la del perceptrón simple. Lo único que variará es que, como podremos tener varias capas, la salida de cada capa será la entrada de la siguiente, por lo que lo tendremos que implementar como un bucle de inferencias capa a capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc391dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        # Matriz de pesos capa 1: (filas: entradas, columnas: salidas)\n",
    "        self.W1 = np.random.uniform(-0.5, 0.5, (n_inputs, n_hidden))\n",
    "        self.b1 = np.random.uniform(-0.5, 0.5, (1, n_hidden))\n",
    "        # Matriz de pesos capa 2: (filas: entradas, columnas: salidas)\n",
    "        self.W2 = np.random.uniform(-0.5, 0.5, (n_hidden, n_outputs))\n",
    "        self.b2 = np.random.uniform(-0.5, 0.5, (1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función sigmoidal\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos la salida de la capa 1\n",
    "        S1 = self.activation(X @ self.W1 + self.b1)\n",
    "        # Calculamos la salida de la capa 2\n",
    "        S2 = self.activation(S1 @ self.W2 + self.b2)\n",
    "        return S2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc781b9",
   "metadata": {},
   "source": [
    "Su funcionamiento sería el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos las entradas (3)\n",
    "X = np.array([1, 2, 3])\n",
    "# Creamos el modelo, del que obtendremos dos salidas dadas las entradas\n",
    "model = MultilayerPerceptron(n_inputs=3, n_hidden=2, n_outputs=2)\n",
    "# Inferimos a ver qué sale\n",
    "ŷ = model.inference(X)\n",
    "print(ŷ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975b31f",
   "metadata": {},
   "source": [
    "Ya tenemos la inferencia programada. Ahora vamos con el algoritmo a través del que aprende la red. Ya hemos visto que la regla delta no nos vale porque para las capas ocultas no sabemos la salida esperada y, por tanto, no sabemos lo que nos estamos equivocando en ellas. Usaremos un truco, que es usar el error de las capas posteriores para estimar el error de la capa en la que nos encontramos, y usar la derivada de la función de activación para saber hacia qué punto desciende el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb3f8a",
   "metadata": {},
   "source": [
    "### Regla delta generalizada (_backpropagation_) y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181a325",
   "metadata": {},
   "source": [
    "Consiste en propagar desde la última capa hasta la primera el error existente entre el valor $ŷ$ que devuelve la red para la entrada $X$ y el valor de salida esperado $y$.\n",
    "\n",
    "Lo primero que hay que hacer es calcular el error cometido en cada una de las capas para actualizar sus correspondientes pesos. La clave aquí es que hay que calcular **primero el error de la última capa**, y luego el error en las capas anteriores a partir del error inmediatamente posterior. Este error se denote como $\\vec{\\delta^(k)}$ y se define como sigue:\n",
    "\n",
    "$$\n",
    "\\vec{\\delta^{(k)}} =\n",
    "  \\left\\{\n",
    "    \\begin{array}{lcc}\n",
    "      &(y - ŷ) &\\odot f'_a(S^(k))                              & si & k = L \\\\\n",
    "      &\\vec{\\delta^{(k+1)}} \\cdot W^{(k+1)T} &\\odot f'_a(S^(k)) & si & k < L\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "$$\n",
    "\n",
    "Tras calcular los errores de todas las capas, las matrices de cambio de pesos se definen de forma muy parecida a la regla delta, sólo que con los nuevos errores:\n",
    "\n",
    "$$\n",
    "\\Delta W^{(k)} = \\alpha S^{(k-1)T} \\delta^{(k)}\n",
    "$$\n",
    "\n",
    "Con todos los $\\Delta W^{(k)}$ calculados podemos actualizar los pesos de cada capa $k$ de la red. De esta manera habríamos realizdo un paso de aprendizaje en nuestro proceso de entrenamiento.\n",
    "\n",
    "Ahora implementaremos tanto el algoritmo de aprendizaje como el proceso de entrenamiento en nuestro perceptrón, ya que este no cambia: al ser un esquema de aprendizaje supervisado, el principio es el mismo. Además, implementaremos un nuevo indicador del error, el RMSE, ya que al ser la función de activación una sigmoidal, jamás llegará a los valores 0 o 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs):\n",
    "        # Matriz de pesos capa 1: (filas: entradas, columnas: salidas)\n",
    "        self.W1 = np.random.uniform(-0.5, 0.5, (n_inputs, n_hidden))\n",
    "        self.b1 = np.random.uniform(-0.5, 0.5, (1, n_hidden))\n",
    "        # Matriz de pesos capa 2: (filas: entradas, columnas: salidas)\n",
    "        self.W2 = np.random.uniform(-0.5, 0.5, (n_hidden, n_outputs))\n",
    "        self.b2 = np.random.uniform(-0.5, 0.5, (1, n_outputs))\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función sigmoidal\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def d_activation(self, X):\n",
    "        # Derivada de la función de activación\n",
    "        return X * (1 - X)\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos la salida de la capa 1\n",
    "        self.S1 = self.activation(X @ self.W1 + self.b1)\n",
    "        # Calculamos la salida de la capa 2\n",
    "        self.S2 = self.activation(self.S1 @ self.W2 + self.b2)\n",
    "        return self.S2\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos cuál es la salida para la entrada suministrada\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ella, calculamos el error y la matriz de actualización de la última capa\n",
    "        d2 = (y - ŷ) * self.d_activation(ŷ)\n",
    "        dW2 = alpha * self.S1.T @ d2\n",
    "        db2 = alpha * np.ones((1, d2.shape[0])) @ d2\n",
    "        # Lo mismo pero con la primera capa\n",
    "        d1 = d2 @ self.W2.T * self.d_activation(self.S1)\n",
    "        dW1 = alpha * X.T @ d1\n",
    "        db1 = alpha * np.ones((1, d1.shape[0])) @ d1\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        self.W1 = self.W1 + dW1\n",
    "        self.b1 = self.b1 + db1\n",
    "        self.W2 = self.W2 + dW2\n",
    "        self.b2 = self.b2 + db2\n",
    "    \n",
    "    def train(self, X, y, epochs, alpha, trace=1):\n",
    "        for epoch in range(0, epochs):\n",
    "            if epoch % trace == 0:\n",
    "                accuracy, error = self.measures(X, y)\n",
    "                print(f'Epoch {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "            self.learn(X, y, alpha)\n",
    "        accuracy, error = self.measures(X, y)\n",
    "        print(f'End -> {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "    \n",
    "    def measures(self, X, y):\n",
    "        ŷ = self.inference(X)\n",
    "        accuracy = (y == ŷ).mean()\n",
    "        rmse = np.sqrt(np.mean((y - ŷ)**2))\n",
    "        return accuracy, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b2ce8",
   "metadata": {},
   "source": [
    "Hay un detalle a la hora de actualizar los bias. Sólo hay un bias por neurona, por lo que si trabajamos con conjuntos de datos en lugar de ejemplos sueltos, hay que tenerlo en cuenta. Por eso se multiplica por un vector de 1s de la misma longitud que la de neuronas.\n",
    "\n",
    "Ahora vamos a probar a entrenar nuestro perceptrón multicapa para una puerta OR de tres entradas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_AND = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 1, 1, 1],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 1, 1, 1],\n",
    "])\n",
    "X = DATASET_AND[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_AND[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = MultilayerPerceptron(n_inputs=3, n_hidden=2, n_outputs=1)\n",
    "model.train(X, y, 1000, 0.5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ee9ab",
   "metadata": {},
   "source": [
    "Veamos qué tal predice nuestro conjunto de datos de la puerta AND tras el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014624c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = model.inference(X)\n",
    "np.piecewise(ŷ, [ŷ < 0.5, 0.5 <= ŷ], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04410381",
   "metadata": {},
   "source": [
    "Bueno, parece que aprende. Vamos a ver qué tal lo hace con la puerta XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = MultilayerPerceptron(n_inputs=2, n_hidden=3, n_outputs=1)\n",
    "model.train(X, y, 1000, 0.5, 100)\n",
    "ŷ = model.inference(X)\n",
    "np.piecewise(ŷ, [ŷ < 0.5, 0.5 <= ŷ], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca613fb",
   "metadata": {},
   "source": [
    "¡Fantástico! ¡Parece que lo ha aprendido! Acabamos de resolver el problema que causó que durante una decada ni se hablase de redes neuronales. Hablamos de uno de los múltiples [Inviernos de la IA](https://en.wikipedia.org/wiki/AI_winter). En este en concreto, se abandonó durante algo más de una década la investigación en redes neuronales debido a las limitaciones del perceptrón.\n",
    "\n",
    "Ahora vamos a continuar con nuestro perceptrón multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19407a",
   "metadata": {},
   "source": [
    "### MLP con varias capas ocultas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16964d35",
   "metadata": {},
   "source": [
    "Una pequeña vuelta de tuerca a nuestra implementación. Con una única capa oculta nos basta para aproximar cualquier función (son [aproximadores universales](https://en.wikipedia.org/wiki/Universal_approximation_theorem) de funciones), pero no son suficientes para generalizar. De hecho, más capas ocultas con menos neuronas en total suelen resolver mejor los problemas gracias a su capacidad de generalización.\n",
    "\n",
    "Por tanto, reimplementaremos el perceptrón, esta vez para que admita un número indefinido de capas y neuronas. Concretamente, en el constructor se recibirá una lista de enteros cuyo primer valor será el número de valores de entrada, su último valor el número de neuronas de salida y los valores intermedios el número de neuronas de cada una de las capas. Por ejemplo, `layers = [2, 3, 4, 1]` se correspondería con 2 neuronas de entrada, una capa oculta de 3 neuronas, otra capa oculta de 4 neuronas y una capa de salida de una neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8189f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilayerPerceptron:\n",
    "    def __init__(self, layers):\n",
    "        # Los pesos de cada capa. Añadimos un elemento vacío al principio para que\n",
    "        # los índices se correspondan con los de las funciones.\n",
    "        self.W = [None] + [\n",
    "            np.random.uniform(-0.5, 0.5, (prev_neurons, curr_neurons))\n",
    "            for prev_neurons, curr_neurons in zip(layers[:-1], layers[1:])\n",
    "        ]\n",
    "        # Los bias de cada capa. Lo mismo que antes con el elemento vacío al ppio.\n",
    "        self.b = [None] + [\n",
    "            np.random.uniform(-0.5, 0.5, (1, curr_neurons))\n",
    "            for curr_neurons in layers[1:]\n",
    "        ]\n",
    "        # La caché de salidas intermedias\n",
    "        self.S = [None for _ in layers]\n",
    "\n",
    "    def activation(self, X):\n",
    "        # Función de activación: función sigmoidal\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def d_activation(self, X):\n",
    "        # Derivada de la función de activación\n",
    "        return X * (1 - X)\n",
    "        \n",
    "    def inference(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # La salida 0 será la entrada a la red\n",
    "        self.S[0] = X\n",
    "        # El resto de salidas se calculan a partir de la salida anterior\n",
    "        for i in range(1, len(self.S)):\n",
    "            self.S[i] = self.activation(self.S[i-1] @ self.W[i] + self.b[i])\n",
    "        # La última de nuestras salidas es la salida de la red\n",
    "        return self.S[-1]\n",
    "    \n",
    "    def learn(self, X, y, alpha):\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=0)\n",
    "        # Calculamos todas las salidas de nuestra red\n",
    "        ŷ = self.inference(X)\n",
    "        # Con ellas, vamos calculando los sucesivos errores y matrices de\n",
    "        # actualización. Comenzamos por la última capa:\n",
    "        δ = (y - ŷ) * self.d_activation(ŷ)\n",
    "        δW = [alpha * self.S[-2].T @ δ]\n",
    "        δb = [alpha * np.ones((1, δ.shape[0])) @ δ]\n",
    "        # Seguimos por las capas intermedias hasta el principio de la red\n",
    "        for i in range(len(self.S) - 2, 0, -1):\n",
    "            δ = δ @ self.W[i+1].T * self.d_activation(self.S[i])\n",
    "            δW.append(alpha * self.S[i-1].T @ δ)\n",
    "            δb.append(alpha * np.ones((1, δ.shape[0])) @ δ)\n",
    "        # Por último, actualizamos los pesos de nuestra red\n",
    "        for i, (δW, δb) in enumerate(zip(reversed(δW), reversed(δb)), 1):\n",
    "            self.W[i] = self.W[i] + δW\n",
    "            self.b[i] = self.b[i] + δb\n",
    "    \n",
    "    def train(self, X, y, epochs, alpha, trace=1):\n",
    "        for epoch in range(1, epochs):\n",
    "            if epoch % trace == 0:\n",
    "                accuracy, error = self.measures(X, y)\n",
    "                print(f'Epoch {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "            self.learn(X, y, alpha)\n",
    "        accuracy, error = self.measures(X, y)\n",
    "        print(f'End -> {epoch}: Accuracy: {accuracy}, RMSE: {error}')\n",
    "    \n",
    "    def measures(self, X, y):\n",
    "        ŷ = self.inference(X)\n",
    "        accuracy = (y == ŷ).mean()\n",
    "        rmse = np.sqrt(np.mean((y - ŷ)**2))\n",
    "        return accuracy, rmse\n",
    "\n",
    "\n",
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "model = MultilayerPerceptron([2, 2, 2, 1])\n",
    "model.train(X, y, 10000, 0.5, 1000)\n",
    "ŷ = model.inference(X)\n",
    "np.piecewise(ŷ, [ŷ < 0.5, 0.5 <= ŷ], [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2e0b3",
   "metadata": {},
   "source": [
    "El problema del XOR tiene bastantes mínimos locales que hacen que en ocasiones el entrenamiento se quede estancado en un punto concreto. Por ello, probablemente se necesiten varias ejecuciones del entrenamiento para tener un modelo que sea capaz de clasificar esta puerta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669ae1c",
   "metadata": {},
   "source": [
    "## Implementación con PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0d89a",
   "metadata": {},
   "source": [
    "Hasta ahora hemos implementado desde cero un perceptrón y un perceptrón multicapa. Sin embargo, existen bibliotecas de alto nivel que nos permiten crear y entrenar redes neuronales de manera más eficiente. De hecho, serán prácticamente esenciales según queramos trabajar con modelos más complejos. Una de las bibliotecas más populares para este propósito es PyTorch que, aunque no es la única, sí que es de las más usadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030ea27",
   "metadata": {},
   "source": [
    "### Conjunto de datos sobre el que trabajar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cab3a8",
   "metadata": {},
   "source": [
    "Ahora estamos trabajando con modelos que aprenden bajo un esquema de aprendizaje supervisado por lo que necesitamos un conjunto de datos con entradas y sus salidas esperadas de los que aprender.\n",
    "\n",
    "La biblioteca `torchvision` es parte de PyTorch, y entre otras cosas, nos ofrece una [colección de _datasets_ populares](https://pytorch.org/vision/stable/datasets.html) como [MNIST](https://en.wikipedia.org/wiki/MNIST_database) o [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). De ellos vamos a usar MNIST, un conjunto de 70000 imágenes (60000 en el conjunto de entrenamiento, 10000 en el conjunto de test) de dígitos escritos a mano de $28 \\times 28$ píxeles junto con su correspondiente etiqueta indicando qué número es exactamente.\n",
    "\n",
    "<center>\n",
    "<figure class=\"image\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" alt=\"Conjunto de datos MNIST\" />\n",
    "    <figcaption><em><strong>Figura 1.</strong>Ilustración de imágenes de ejemplo del conjunto de datos MNIST. Fuente: [Wikipedia](https://es.wikipedia.org/wiki/Base_de_datos_MNIST).</em></figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8f007-1e02-4830-b01e-f3ea1db52fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación que usaremos más adelante. Convertirá PIL.Image a tensor con\n",
    "#  los valores normalizados\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "# Obtenemos el MNIST, como objetos de la clase `torch.utils.data.Dataset`\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root=DATASETS_DIR,  # Directorio donde están (o donde descargar) el dataset\n",
    "    train=True,  # Las imagenes de entrenamiento\n",
    "    download=True,  # En caso de que no exista, queremos descargarlo\n",
    "    transform=transform,  # Para traducir las imagenes. Podíamos usar solo\n",
    "                          #  `transforms.ToTensor()`, pero vamos a lo loco y\n",
    "                          #  aplicamos un pipeline entero.\n",
    ")\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root=DATASETS_DIR,\n",
    "    train=False,  # Las imágenes de test\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Creamos dataloaders para los conjuntos de datos, que nos dan una API para\n",
    "#  iterar cómodamente sobre los conjuntos de datos.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_set,  # El conjunto de datos sobre el que iterar\n",
    "    batch_size=64,  # El número de ejemplos que recibimos en cada iteración\n",
    "    shuffle=True,  # Si queremos mezclar el dataset en cada epoch\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=64,\n",
    "    shuffle=False,  # Aquí no nos hace falta mezclar\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44be97c4",
   "metadata": {},
   "source": [
    "Con los conjuntos de datos cargados y preparados, ya tenemos suficiente para trabajar. ¡Vamos allá!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc9b93-bf33-41eb-8df6-36963079ad42",
   "metadata": {},
   "source": [
    "### Definición del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb962f6e",
   "metadata": {},
   "source": [
    "La primera forma que vamos a ver para crear modelos en PyTorch es la API secuencial. Es una forma muy sencilla donde el modelo se crea a  partir de una sucesión de capas y por debajo este las conecta (esto es, las salidas de una capa con las entradas de la siguiente). Por ejemplo, el perceptrón que implementamos anteriormente (bueno, lo más parecido a lo que podemos llegar) se implementaría como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(\n",
    "        in_features=2,  # Cuantas neuronas de entrada, en nuestro caso 2\n",
    "        out_features=3,  # Neuronas de salida de esta capa\n",
    "    ),\n",
    "    nn.Sigmoid(),  # Aplicamos sigmoide a todas las salidas (por separado)\n",
    "    nn.Linear(\n",
    "        in_features=3,  # El número debe igual a las salidas de la anterior\n",
    "        out_features=1,  # Una única salida\n",
    "    ),\n",
    "    nn.Sigmoid(),  # La salida estará en el intervalo (0, 1)\n",
    ")\n",
    "torchsummary.summary(model, input_size=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259f900",
   "metadata": {},
   "source": [
    "No tiene más. Se trata de una arquitectura de dos capas, cada una con una función de activación signoidal. Para entrenar este modelo tenemos que especificar de qué manera calculamos el error (en nuestro caso antes usábamos la diferencia entre valor esperado y valor inferido) y cómo vamos a optimizar (en nuestro caso usábamos nuestra implementación del algoritmo _backpropagation_).\n",
    "\n",
    "Ahora usaremos otra medida de eror, por ejemplo el MSE (no tiene mucho sentido, lo veremos más adelante), y otro algoritmo de optimización, el descenso del gradiente estocástico (SGD, del inglés _stochastic gradient descent_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedf7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # Error cuadrático medio para calcular el error\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89beb117",
   "metadata": {},
   "source": [
    "Con esto podemos entrenar el modelo. Por ejemplo, en el problema de la puerta XOR de antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_XOR = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "])\n",
    "X = DATASET_XOR[:, :-1]  # Entradas: Todas las columnas hasta la última\n",
    "y = DATASET_XOR[:, -1:]  # Salidas: Todas las columnas desde la última\n",
    "\n",
    "# Convertimos las entradas a tensores\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "num_epochs = 10000\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    optimizer.zero_grad()  # Reiniciamos los gradientes\n",
    "    outputs = model(X_tensor)  # Propagamos la entrada hacia la salida\n",
    "    loss = criterion(outputs, y_tensor)  # Calculamos el error en la predicción\n",
    "    loss.backward()  # Retropropagamos el error para determinar los gradientes\n",
    "    optimizer.step()  # Actualizamos los pesos\n",
    "\n",
    "    # Mostrar información cada 1000 épocas\n",
    "    if (epoch + 1) % (num_epochs // 10) == 0:\n",
    "        with torch.no_grad():  # Cuando solo predecimos y no vamos a entrenar,\n",
    "                               #  desactivamos los gradientes.\n",
    "            predictions = (outputs >= 0.5).float()  # será 0 si < 0.5, si no 1\n",
    "            accuracy = (predictions == y_tensor).float().mean()\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "        print(f\"- Loss: {loss.item():.4f}\")\n",
    "        print(f\"- Accuracy: {accuracy.item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788170b6-598d-4301-be1f-84517d8ddfc9",
   "metadata": {},
   "source": [
    "Ahora evaluamos el resultado. ara un problema es matar moscas a cañonazos, pero nos permite entender todo el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0117476-aa56-46d1-9eb1-9d60b56eaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Solo predecir, no queremos los gradientes para nada\n",
    "    outputs = model(X_tensor)\n",
    "    predictions = (outputs >= 0.5).float()\n",
    "    accuracy = (predictions == y_tensor).float().mean()\n",
    "    print(\"Final predictions:\")\n",
    "    print(predictions)\n",
    "    print(f\"Final accuracy: {accuracy.item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160aaa82",
   "metadata": {},
   "source": [
    "Ahora bien, con el conjunto de datos de `mnist` tenemos que hacer algunos cambios porque este modelo no nos vale:\n",
    "\n",
    "1. La entrada es una matriz de $28 \\times 28$, y hasta ahora hemos visto modelos que esperan un vector de entrada. Afortunadamente para esto último PyTorch nos proporciona una capa denominada `Flatten`, que simplifica nuestros datos «aplanando» la información de la estructura 2D de la imagen  en un único vector de una dimensión.\n",
    "2. Una imagen no es una puerta OR. Mejor aumentamos un poco el tamaño de la capa oculta.\n",
    "3. La salida de nuestro modelo no es $0$ o $1$. Es un valor de $0$ a $9$. Si fuese una clasificación binaria valdría, pero es una clasificación denominada «multiclase» (solo una clase es válida para una entrada concreta). Para estos casos, se suele trabajar con varias clasificaciones binarias, una para cada clase. Como tenemos $10$ posibles valores de salida, usaremos $10$ neuronas, una para cada clase. En otros _frameworks_, para problemas de clasificación multiclase se usan aquí dos funciones por separado, **activación final**, que suele ser una función _softmax_ o _log-softmax_, **y error** o «pérdida» (del inglés _loss_), que suele ser la entropía cruzada (del inglés _cross entropy_. Sin embargo, en PyTorch la función de _loss_ para la entropía cruzada ya lleva incorporada la capa de activación _log-softmax_ así que no hace falta añadirla.\n",
    "\n",
    "Con estos cambios nuestro modelo quedaría como sigue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1086230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),  # Pasamos de un  tensor (28, 28) a uno (784,)\n",
    "    nn.Linear(in_features=28*28, out_features=32),  # 28*28 = 784 entradas\n",
    "    nn.Sigmoid(),  # Aplicamos sigmoide a todas las salidas (por separado)\n",
    "    nn.Linear(in_features=32, out_features=10),  # 10 clases, de la 0 a la 9.\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # La función de error para la clasificación\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "torchsummary.summary(model, input_size=(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a81d2ec",
   "metadata": {},
   "source": [
    "Es curioso ver cómo se ha disparado el número de parámetros con solo aumentar un poco el número de neuronas. Bueno, veamos qué tal se comporta con el conjunto de entrenamiento de `mnist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'loss': [], 'accuracy': []}\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:  # Usamos todas las imágenes cada epoch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()  # Acumulamos todos los loss para el total\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)  # Número de imagenes procesadas este batch\n",
    "        correct += (predicted == labels).sum().item()  # Número de aciertos\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['accuracy'].append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09407a3f",
   "metadata": {},
   "source": [
    "Esto ya ha tardado  más, ¿eh? Claro, son bastantes imágenes, es normal.\n",
    "\n",
    "Hemos guardado en el diccionario history un histórico de todos los indicadores de nuestro proceso de entrenamiento (incluidas las métricas especificadas en el método `compile`) _epoch_ por _epoch_. Podemos aprovechar este objeto para imprimir por pantalla la evolución del entrenamiento, lo que nos daría información acerca de cómo ha ido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b3769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history).plot()\n",
    "plt.xlabel('Epoch num.')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd81063",
   "metadata": {},
   "source": [
    "Esta gráfica nos dice más o menos tres cosas:\n",
    "\n",
    "1. El error (_loss_) va bajando durante el entrenamiento; eso es bueno.\n",
    "2. La exactitud (_accuracy_) va subiendo; suele venir de la mano con la bajada del _loss_, así que también es bueno.\n",
    "\n",
    "A la vista de los resultados, parece que el modelo acierta más o menos un $97,5\\%$ de los casos. Ya veremos más adelante detalles sobre el entrenamiento y por qué son interesantes los conjuntos de validación. Lo importante ahora es que, si damos como bueno este modelo, el siguienter (y último) paso para determinar si es apto para usarse en el mundo real sería comprobar con el conjunto de test. Veamos cómo se comporta con este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5ed83",
   "metadata": {},
   "source": [
    "¡Aproximadamente un 97% de exactitud! La verdad es que no está mal. O sí, no sé, la verdad es que depende del problema. Aquí nos está diciendo que de $10000$ imágenes hay $300$ que no ha clasificado bien. Parece que un $3\\%$ de error está bastante bien en un problema de reconocimiento de imágenes, pero a lo mejor en un problema de reconocer un cáncer de mama no es una estadística muy halagüeña.\n",
    "\n",
    "Pero no nos preocupemos, hay más modelos que aprenderemos para abordar diferentes casos que nos ayudarán en multitud de tareas. Lo importante es ir llenando nuestra caja de herramientas de técnicas y de intuiciones de cómo y cuándo usarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89064f29",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01c480",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89233727",
   "metadata": {},
   "source": [
    "En este _notebook_ hemos recorrido lo más básico del aprendizaje profundo. Con el perceptrón simple vimos cómo funciona un modelo lineal básico y entendimos sus limitaciones frente a problemas complejos. Luego, al estudiar el perceptrón multicapa, observamos que añadir capas ocultas **y usar funciones de activación no lineales** permite resolver problemas que los modelos lineales no pueden.\n",
    "\n",
    "La implementación desde cero nos ayudó a comprender el proceso de aprendizaje y la actualización de pesos, mientras que el uso de PyTorch demuestra que se pueden construir y entrenar redes neuronales de forma mucho más sencilla. De ahora en adelante comenzaremos a ver temas más interesantes, pero con la base ya asentada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147861b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc657f4",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d54d756",
   "metadata": {},
   "source": [
    "[1] Guía para la creación de capas y modelos personalizados (<https://www.tensorflow.org/guide/keras/custom_layers_and_models>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582efec2",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<div><img style=\"float: right; width: 120px; vertical-align:top\" src=\"https://mirrors.creativecommons.org/presskit/buttons/88x31/png/by-nc-sa.png\" alt=\"Creative Commons by-nc-sa logo\" />\n",
    "\n",
    "[Volver al inicio](#top)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
